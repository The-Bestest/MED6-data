---
title: "Analysis"
output: html_notebook
---

```{r Load packages, include=FALSE}
library(tidyverse)
library(tidymodels)
library(skimr)
library(lubridate)  # for handling dates and time
library(Hmisc)    # correlation
library(corrplot)
library(PerformanceAnalytics)
library(RColorBrewer)
library(GGally)
library(DescTools) # ICC
#library(Rmisc) # summarySE
library(ggbeeswarm)
```
```{r Define functions, include=FALSE}
load_bci_data <- function(fileNamePattern, columns) {
  # list all files in data folder, that end with filename pattern
  list.files(recursive=TRUE, path = "./data", pattern = fileNamePattern, full.names = T) %>%
    tibble(filename = .) %>%
    # load the contents of each CSV file
    mutate(file_contents = map(filename, ~read_csv(file.path(.), na = "NULL", col_types = columns))) %>%
    # extract the nested columns into a flat table
    unnest(cols=-filename) %>%
    # extract the participant label and the Condition from the file path
    separate(col=filename,sep="/",into=c("start","folder","Participant","Condition","filename")) %>%
    # remove the leading "P" from participant label, e.g. P10 -> 10
    mutate(
      Participant=as.numeric(str_replace(Participant,"P","")), Condition=as.factor(Condition),
    ) %>%
    dplyr::group_by(Participant, Condition) %>%
    mutate(
      vis_t_time = as.POSIXlt(Timestamp, format = "%Y-%m-%d %H:%M:%OS"),
      Timestamp = seconds(vis_t_time)) %>%
    ungroup()
}

flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
    )
}

plotCorrelation <- function(data, x, y, xLabel, yLabel) {
  data  %>%
    ggplot(aes(x=x,y=y, colour=Condition, fill=Condition))+
    theme_bw(base_size = 10) +
    geom_point(position=position_jitter(h=0.08, w=0.08), shape = 21, alpha = 0.5, size = 3) +
    expand_limits(x=c(1,7), y=c(1, 7))+
    scale_color_manual(values=c("red","blue")) +
    scale_fill_manual(values=c("red","blue")) +
    xlab(label = xLabel) +
    ylab(label = yLabel) +
    labs(fill = "Conditions", colour = "Conditions")+
    geom_smooth(method = "lm", fill = NA)
}

# TODO: ask Hendrik for the paper with best plotting practices again
# Steffen says this is a fake boxplot
plotBoxplotLikert <- function(data, y, yColumnName, yLabel, condition1Label, condition2Label) {
  ID <- 1:7 # 7-Likert scale

  #summaryData <- summarySE(data, measurevar=yColumnName, groupvars=c("Condition"))
  #colnames(summaryData)[3] = "y"

  #boxPlot <- ggplot(summaryData, aes(Condition, y, colour=Condition)) +
   # theme_classic(base_size = 20) +
    #geom_boxplot(aes(lower = y - ci, upper = y + ci, middle = y, ymin = y - 3*ci, ymax = y + 3*ci),
   #   stat = "identity", color="#454545", width=.5, alpha=0) +
   # geom_beeswarm(data = gameSummary, priority='density',cex=3, color="gray", aes(size=3, stroke=1)) +
    #scale_x_discrete(limits=c(), labels=c(condition1Label, condition2Label)) +
   # scale_y_continuous("ownership", limits=c(1, 7.5), labels = as.character(ID), breaks = ID) +
   # ylab(yLabel) + xlab("") +
   # theme(legend.position="none")


  #boxPlotData <- ggplot_build(boxPlot)$data[[1]]
  # Add red mean median lines
  # TODO: is it alright to compute mean for nonparametric data?
 # boxPlot <- boxPlot + geom_segment(data=boxPlotData, aes(x=xmin, xend=xmax, y=middle, yend=middle), colour="red", size=2)

  #boxPlot
}

```

## BCI - Continuous and Discrete Input

```{r Load pre-experiment questionnaire data, echo=FALSE, results='hide'}
preQuestionnaire <- as_tibble(read.csv(file.path("./data","preQuestionnaire.csv"),stringsAsFactors=FALSE)) %>%
  mutate_if(is.character, stringr::str_replace_all, pattern = " ", replacement = "_")
preQuestionnaire <- preQuestionnaire %>%
  pivot_longer(cols = -X, names_to = "Participant") %>%
  mutate_if(is.character, stringr::str_replace_all, pattern = " ", replacement = "_") %>%
  mutate_if(is.character, stringr::str_replace_all, pattern = "P", replacement = "") %>%
  mutate(Participant = as.numeric(Participant)) %>%
  pivot_wider(names_from = X)

```

```{r Load post-experiment questionnaire data, echo=FALSE, results='hide'}
postQuestionnaire <- as_tibble(read.csv(file.path("./data","postQuestionnaire.csv")))
orderNumber <- rep(c(1,2,2,1),10)
postQuestionnaire <- cbind(postQuestionnaire, orderNumber)
```

```{r Load game data, echo=FALSE, results='hide'}
game_columns = cols(
  .default = col_double(),
  Event = col_character(),
  Timestamp = col_datetime(format = ""),
  SessionID = col_character(),
  Email = col_character(),
  BCIState = col_character(),
  InputWindow = col_character(),
  GameState = col_character(),
  TrialResult = col_character(),
  TrialGoal = col_character(),
  BCIThresholdBuffer = col_character()
)
game <- load_bci_data("*Game.csv", game_columns)
game <- game %>%
  # convert time to a proper Timestamp object
  dplyr::group_by(Participant, Condition) %>%
  mutate(
    GameIsOn = ifelse(Event == "GameRunning", 1, 0),
    GameIsOn = cumsum(GameIsOn)) %>%
    arrange(Participant,Condition,Timestamp) %>%
    dplyr::mutate(InputWindowNum = dplyr::lag(ifelse(Event == "GameDecision", 1, 0),default=0)) %>%
    dplyr::mutate(InputWindowNum = cumsum(InputWindowNum)) %>%
    ungroup()
game <- game %>%
  select(Participant, Condition, InputWindowNum,Timestamp) %>%
  dplyr::group_by(Participant, Condition, InputWindowNum) %>%
  dplyr::summarise(StartTime = min(Timestamp)) %>%
  right_join(game) %>%
  mutate(TimeSinceIWstart = ifelse(TrialResult == "AccInput",Timestamp - StartTime,NA))

gameSummary <- game %>%
  dplyr::mutate(successes = ifelse(TrialResult == "AccInput", 1, 0)) %>%
  dplyr::group_by(Participant, Condition) %>%
  dplyr::summarize(accPerc = sum(successes,na.rm = TRUE) / max(InputWindowNum), activateDelay = mean(TimeSinceIWstart,na.rm = TRUE))

# Filter game columns, add columns here on need-only basis
game <- game[c("Participant", "Condition", "Timestamp", "GameIsOn", "InputWindowNum", "BCIConfidence")]
```

```{r Load meta data, echo=FALSE, results='hide'}
meta_columns = cols(
  SessionID = col_character(),
  Timestamp = col_datetime(format = ""),
  Framecount = col_double(),
  Email = col_character(),
  DeviceID = col_character(),
  FabInputTrials = col_double(),
  AccInputTrials = col_double(),
  RejInputTrials = col_double(),
  Trials = col_double(),
  InterTrialInterval_sec = col_double(),
  InputWindow_sec = col_double(),
  noInputReceivedFabAlarm_sec = col_double(),
  FabAlarmVariability_sec = col_double(),
  ConfidenceThreshold = col_double(),
  BCIProcessingMode = col_character(),
  ConsecutiveThresholdBufferSize = col_double()
)

meta <- load_bci_data("*Meta.csv", meta_columns)

# Filter meta columns, add columns here on need-only basis
meta <- meta[c("Participant", "Condition", "Timestamp")]
```

```{r Load sample data, echo=FALSE, results='hide'}
sample_columns = cols(
  Event = col_character(),
  Timestamp = col_datetime(format = ""),
  Framecount = col_double(),
  SessionID = col_character(),
  Email = col_character(),
  BCIConfidence = col_double(),
  BCIState = col_character()
)
sample <- load_bci_data("*Sample.csv", sample_columns)

# Filter meta columns, add columns here on need-only basis
sample <- sample[c("Participant", "Condition", "Event", "Timestamp", "BCIConfidence")]
```

```{r Merge all data, echo=FALSE, results='hide'}
gameSummary <-gameSummary %>%
  merge(postQuestionnaire) %>%
  merge(preQuestionnaire)
gameSummary <- merge(gameSummary,postQuestionnaire)
```

```{r Parittion data}
discrete_label <- "Body" # TODO: fix the label
continuous_label <- "Blocks" # TODO: fix the label
ParticipantOrder1 <- gameSummary %>% filter(orderNumber == 1)
Discrete1 <- ParticipantOrder1 %>% filter(Condition==discrete_label)
Continuous1 <- ParticipantOrder1 %>% filter(Condition==continuous_label)
ParticipantOrder2 <- gameSummary %>% filter(orderNumber == 2)
Discrete2 <- ParticipantOrder2 %>% filter(Condition==discrete_label)
Continuous2 <- ParticipantOrder2 %>% filter(Condition==continuous_label)
```

### 1. Distributions

Overview of the game data and post questionnaire data for quick lookup of means, standard deviations, quantiles and histograms for every measured variable per each condition.
```{r Quick overview}
gameSummary %>%
  select(-Participant) %>%
  group_by(Condition) %>%
  skim()

postQuestionnaire %>%
  select(-Participant) %>%
  group_by(Condition) %>%
  skim()
```


### 2. Unsystematic manipulations check

Check parametric data for normality in order to find out whether we can use parametric analysis on them.
```{r Check parametric data for normality}
# Check performance (accPerc), Perceived Successes, ReportedAvgAttempts for normality
# We don't need to check for variance with Levene's test, as Welch's test takes care of that.
# https://daniellakens.blogspot.com/2015/01/always-use-welchs-t-test-instead-of.html

# Is the date in each order parametric?
# YES if p > 0.05
normalityCheck <- gameSummary %>%
  select(accPerc, PerceivedSuccesses, ReportedAvgAttempts, Condition, orderNumber) %>%
  gather(key = variable, value = value, -Condition, -orderNumber) %>%
  group_by(Condition, orderNumber, variable) %>%
  summarise(value=list(value)) %>%
  group_by(variable) %>%
  mutate(
    p_value = shapiro.test(unlist(value))$p.value,
    statistic = shapiro.test(unlist(value))$statistic
  )
# method from: https://sebastiansauer.github.io/multiple-t-tests-with-dplyr/
```
```{r Counter balancing for parametric data - Randomization check}
# Does it matter for actual performance, perceived performance and reported average attempt if discrete condition was first?
parametricCheck <- gameSummary %>%
  select(accPerc, PerceivedSuccesses, ReportedAvgAttempts, Condition, orderNumber) %>%
  gather(key = variable, value = value, -Condition, -orderNumber) %>%
  group_by(Condition, orderNumber, variable) %>%
  summarise(value=list(value)) %>%
  spread(orderNumber, value) %>% 
  group_by(variable)  %>%
  rename(order1 = 3, order2 = 4) %>%
  mutate(
    p_value = t.test(unlist(order1), unlist(order2))$p.value,
    statistic = t.test(unlist(order1), unlist(order2))$statistic
  )
# method from: https://sebastiansauer.github.io/multiple-t-tests-with-dplyr/
```


```{r Counter balancing for non-parametric data in post-questionnaire- Randomization check}
# Does it matter for our non-parametric data in post questionnaire if discrete condition was first?
nonParametricCheckPost <- gameSummary %>%
  select(Condition, orderNumber, SoO, SoA, Difficulty, Frustration, GeneralComfort, MentalEffort, PhysicalEffort, Proprioception) %>%
  gather(key = variable, value = value, -Condition, -orderNumber) %>%
  group_by(Condition, orderNumber, variable) %>%
  summarise(value=list(value)) %>%
  spread(orderNumber, value) %>% 
  group_by(variable)  %>%
  rename(order1 = 3, order2 = 4) %>%
  mutate(
    p_value = wilcox.test(unlist(order1), unlist(order2), paired=TRUE, exact=FALSE)$p.value,
    statistic = wilcox.test(unlist(order1), unlist(order2), paired=TRUE, exact=FALSE)$statistic
  )
# method from: https://sebastiansauer.github.io/multiple-t-tests-with-dplyr/
```

```{r Counter balancing for non-parametric data in pre-questionnaire- Randomization check}
# Does it matter for our non-parametric data in pre questionnaire if discrete condition was first?
nonParametricCheckPre <- gameSummary %>%
  # Pick all columns that start with Q - those are the ones from pre-questionnaire
  select(starts_with('Q'), Condition, orderNumber) %>%
  filter(Condition==discrete_label)  %>%
  gather(key = variable, value = value, -Condition, -orderNumber) %>%
  group_by(orderNumber, variable) %>%
  summarise(value=list(value)) %>%
  spread(orderNumber, value) %>%
  group_by(variable) %>%
  rename(order1 = 2, order2 = 3) %>%
  mutate(
    p_value = wilcox.test(unlist(order1), unlist(order2), paired=TRUE, exact=FALSE)$p.value,
    statistic = wilcox.test(unlist(order1), unlist(order2), paired=TRUE, exact=FALSE)$statistic
  )
# method from: https://sebastiansauer.github.io/multiple-t-tests-with-dplyr/
```
```{r Intraclass correlation check}
# Todo: is thi correct? How to interpret this?
iccCheckPre <- gameSummary %>%
  select(starts_with('Q'))
ICC(iccCheckPre)

iccCheckPost <- gameSummary %>%
  select(Difficulty, Frustration, GeneralComfort, MentalEffort, PhysicalEffort, Proprioception)
ICC(iccCheckPost)
```

### 3. Correlations

Correlation matrices for all data and per-condition data. Use this to find variable relationships you want to investigate further.
```{r Correlation}
# check out this web page on easy summaries for correlations:
# http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software
filter_out = c(1,2,13,15) # columns to filter out

# Correlation matrix between every question and performance
chart.Correlation(gameSummary[,-filter_out], histogram=TRUE, pch=19)

# Data for per-condition correlation matrix between every question and performance
correlationMatrix <- Hmisc::rcorr(as.matrix(gameSummary[,-filter_out]))
correlationMatrix <- flattenCorrMatrix(correlationMatrix$r, correlationMatrix$P)

# Per-condition correlation matrix between every question and performance
for(condition in unique(gameSummary$Condition)) {
  corrplot(cor(gameSummary[gameSummary$Condition==condition,-filter_out]), type="upper",col=brewer.pal(n=8, name="RdYlBu"))
}
```

Investigate the interesting correlations further.
```{r Correlation checks}
# Template:
# cor.test(VAR1, VAR2, method="spearman", exact = FALSE)
```

### 4. Test our hypothesis
Assuming we have all data in order, we can check our hypothesis.
```{r Hypothesis checks}
hypothesisCheck <- gameSummary %>%
  select(Condition, SoO, SoA, Difficulty, Frustration, GeneralComfort, MentalEffort, PhysicalEffort, Proprioception) %>%
  gather(key = variable, value = value, -Condition) %>%
  group_by(Condition, variable) %>%
  summarise(value=list(value)) %>%
  spread(Condition, value) %>%
  group_by(variable)  %>%
  mutate(
    # TODO: Rename Body and Blocks to actual condition names once we have new data
    p_value = wilcox.test(unlist(Body), unlist(Blocks), paired=TRUE, exact=FALSE)$p.value,
    statistic = wilcox.test(unlist(Body), unlist(Blocks), paired=TRUE, exact=FALSE)$statistic
  )
```


### 5. Plotting ground

```{r Plot correlations}
# Example: Plot correlations between SoA and SoO
# plotCorrelation(gameSummary, gameSummary$SoA, gameSummary$SoO, "SoA", "SoO")
```

```{r Plot boxplots}
# Example: Plot boxplot of SoA
# print(plotBoxplotLikert(gameSummary, gameSummary$SoA, "SoA", "agency", discrete_label, continuous_label))
```